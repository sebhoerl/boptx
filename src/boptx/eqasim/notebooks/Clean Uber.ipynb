{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20ce39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57eac318",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_input_file = \"../data/raw/iris_2017/CONTOURS-IRIS.shp\"\n",
    "uber_spatial_input_file = \"../data/raw/uber/paris_iris.json\"\n",
    "uber_monthly_input_file = \"../data/raw/uber/paris-iris-2019-3-OnlyWeekdays-MonthlyAggregate.csv\"\n",
    "uber_hourly_input_file = \"../data/raw/uber/paris-iris-2019-3-OnlyWeekdays-HourlyAggregate.csv\"\n",
    "\n",
    "daily_output_file = \"../data/uber_daily.csv\"\n",
    "hourly_output_file = \"../data/uber_hourly.csv\"\n",
    "zones_output_file = \"../data/uber_zones.gpkg\"\n",
    "    \n",
    "if \"snakemake\" in locals():\n",
    "    iris_input_file = snakemake.input[\"iris\"]\n",
    "    uber_spatial_input_file = snakemake.input[\"spatial\"]\n",
    "    uber_monthly_input_file = snakemake.input[\"monthly\"]\n",
    "    uber_hourly_input_file = snakemake.input[\"hourly\"]\n",
    "    \n",
    "    daily_output_file = snakemake.output[\"daily\"]\n",
    "    hourly_output_file = snakemake.output[\"hourly\"]\n",
    "    zones_output_file = snakemake.output[\"zones\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a387d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IRIS\n",
    "df_iris = gpd.read_file(iris_input_file)\n",
    "df_iris[\"municipality_id\"] = df_iris[\"INSEE_COM\"]\n",
    "df_iris = df_iris[[\"municipality_id\", \"geometry\"]]\n",
    "df_iris = df_iris.to_crs(\"epsg:2154\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be8f9928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Uber spatial data, the IDs are not the same so we need to figure out to which IRIS they match\n",
    "df_spatial = gpd.read_file(uber_spatial_input_file)\n",
    "df_spatial[\"uber_id\"] = df_spatial[\"MOVEMENT_ID\"].astype(int)\n",
    "df_spatial = df_spatial[[\"uber_id\", \"geometry\"]]\n",
    "df_spatial = df_spatial.to_crs(\"epsg:2154\")\n",
    "df_spatial[\"geometry\"] = df_spatial[\"geometry\"].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "538ada7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uber_id</th>\n",
       "      <th>municipality_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>75101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>75101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>75101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>75101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>75101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>5255</td>\n",
       "      <td>95680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>5256</td>\n",
       "      <td>95680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5256</th>\n",
       "      <td>5257</td>\n",
       "      <td>95680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>5258</td>\n",
       "      <td>95682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258</th>\n",
       "      <td>5259</td>\n",
       "      <td>95690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5260 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uber_id municipality_id\n",
       "0           1           75101\n",
       "1           2           75101\n",
       "2           3           75101\n",
       "3           4           75101\n",
       "4           5           75101\n",
       "...       ...             ...\n",
       "5254     5255           95680\n",
       "5255     5256           95680\n",
       "5256     5257           95680\n",
       "5257     5258           95682\n",
       "5258     5259           95690\n",
       "\n",
       "[5260 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match the IDs\n",
    "df_spatial = gpd.sjoin(df_spatial, df_iris, op = \"within\")\n",
    "df_spatial = df_spatial[[\"uber_id\", \"municipality_id\"]]\n",
    "df_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ce2a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_spatial) == len(df_spatial[\"uber_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c3632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load monthly data\n",
    "df_monthly = pd.read_csv(uber_monthly_input_file)\n",
    "df_monthly = df_monthly.rename(columns = {\n",
    "    \"sourceid\": \"origin_uber_id\",\n",
    "    \"dstid\": \"destination_uber_id\",\n",
    "    \"mean_travel_time\": \"travel_time\"\n",
    "})[[\"origin_uber_id\", \"destination_uber_id\", \"travel_time\"]]\n",
    "\n",
    "df_monthly[\"origin_uber_id\"] = df_monthly[\"origin_uber_id\"].astype(int)\n",
    "df_monthly[\"destination_uber_id\"] = df_monthly[\"destination_uber_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a126e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in municipality information\n",
    "df_monthly = pd.merge(df_monthly, df_spatial.rename(columns = {\n",
    "    \"uber_id\": \"origin_uber_id\",\n",
    "    \"municipality_id\": \"origin_municipality_id\"\n",
    "}), on = \"origin_uber_id\", how = \"inner\")\n",
    "                      \n",
    "df_monthly = pd.merge(df_monthly, df_spatial.rename(columns = {\n",
    "    \"uber_id\": \"destination_uber_id\",\n",
    "    \"municipality_id\": \"destination_municipality_id\"\n",
    "}), on = \"destination_uber_id\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a775bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average over each OD pair\n",
    "df_monthly = df_monthly.groupby([\n",
    "    \"origin_municipality_id\", \"destination_municipality_id\"\n",
    "]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04708c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output\n",
    "df_monthly[[\n",
    "    \"origin_municipality_id\", \"destination_municipality_id\", \"travel_time\"\n",
    "]].to_csv(daily_output_file, sep = \";\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d76a46ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6742245475474c829c186a77443b1b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load hourly data\n",
    "df_hourly = []\n",
    "\n",
    "for df_chunk in tqdm(pd.read_csv(uber_hourly_input_file, usecols = [\n",
    "    \"sourceid\", \"dstid\", \"hod\", \"mean_travel_time\"\n",
    "], dtype = {\n",
    "    \"sourceid\": int, \"dstid\": int, \"hod\": int, \"mean_travel_time\": float\n",
    "}, chunksize = int(1e6)), total = 44):\n",
    "    df_hourly.append(df_chunk)\n",
    "    \n",
    "df_hourly = pd.concat(df_hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e044ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly = df_hourly.rename(columns = {\n",
    "    \"sourceid\": \"origin_uber_id\",\n",
    "    \"dstid\": \"destination_uber_id\",\n",
    "    \"hod\": \"hour\",\n",
    "    \"mean_travel_time\": \"travel_time\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63b0a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of hours available for each pair\n",
    "df_hours = df_hourly.groupby([\"origin_uber_id\", \"destination_uber_id\"]).size().reset_index(name = \"hours\")\n",
    "df_hours = df_hours[df_hours[\"hours\"] == 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58e85963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly[\"temp\"] = int(1e6) * df_hourly[\"origin_uber_id\"] + df_hourly[\"destination_uber_id\"]\n",
    "df_hours[\"temp\"] = int(1e6) * df_hours[\"origin_uber_id\"] + df_hours[\"destination_uber_id\"]\n",
    "\n",
    "df_hourly = df_hourly[df_hourly[\"temp\"].isin(df_hours[\"temp\"].unique())]\n",
    "df_hourly = df_hourly.drop(columns = [\"temp\"])\n",
    "\n",
    "del df_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9130f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in municipality information\n",
    "df_hourly = pd.merge(df_hourly, df_spatial.rename(columns = {\n",
    "    \"uber_id\": \"origin_uber_id\",\n",
    "    \"municipality_id\": \"origin_municipality_id\"\n",
    "}), on = \"origin_uber_id\", how = \"inner\")\n",
    "                      \n",
    "df_hourly = pd.merge(df_hourly, df_spatial.rename(columns = {\n",
    "    \"uber_id\": \"destination_uber_id\",\n",
    "    \"municipality_id\": \"destination_municipality_id\"\n",
    "}), on = \"destination_uber_id\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f336eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average over each OD pair\n",
    "df_hourly = df_hourly.groupby([\n",
    "    \"origin_municipality_id\", \"destination_municipality_id\", \"hour\"\n",
    "])[\"travel_time\"].mean().reset_index(name = \"travel_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e399a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output\n",
    "df_hourly[[\n",
    "    \"origin_municipality_id\", \"destination_municipality_id\", \"hour\", \"travel_time\"\n",
    "]].to_csv(hourly_output_file, sep = \";\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "140c64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write municipalities for matching\n",
    "\n",
    "df_municipalities = df_iris[df_iris[\"municipality_id\"].isin(df_spatial[\"municipality_id\"])].copy()\n",
    "df_municipalities[\"municipality_id\"] = df_municipalities[\"municipality_id\"].astype(int)\n",
    "df_municipalities.to_file(zones_output_file, driver = \"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
